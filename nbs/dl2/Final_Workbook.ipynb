{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librarires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from exp.nb_09 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('boom_doom_wee_dg', re.compile(r'(.)([A-Z][a-z]+)', re.UNICODE))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_camel_re1 = re.compile('(.)([A-Z][a-z]+)')\n",
    "_camel_re2 = re.compile('([a-z0-9])([A-Z])')\n",
    "\n",
    "# Converts camel names to snake names\n",
    "def camel2snake(name):\n",
    "    s1 = re.sub(_camel_re1, r'\\1_\\2', name)\n",
    "    return re.sub(_camel_re2, r'\\1_\\2', s1).lower()\n",
    "\n",
    "c2s = camel2snake(\"BoomDoomWeeDg\")\n",
    "c2s, _camel_re1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Exceptions as flow control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Callback():\n",
    "    _order=0\n",
    "    def set_runner(self, run): self.run=run\n",
    "    def __getattr__(self, k): return getattr(self.run, k) # if cannot find the attribute inside the cb, \n",
    "    #look inside the runner\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        name = re.sub(r'Callback$', '', self.__class__.__name__)\n",
    "        return camel2snake(name or 'callback')\n",
    "    \n",
    "    def __call__(self, cb_name):\n",
    "        f = getattr(self, cb_name, None)\n",
    "        if f and f(): return True\n",
    "        return False\n",
    "\n",
    "class TrainEvalCallback(Callback):\n",
    "    def begin_fit(self):\n",
    "        self.run.n_epochs=0.\n",
    "        self.run.n_iter=0\n",
    "    \n",
    "    def after_batch(self):\n",
    "        if not self.in_train: return\n",
    "        self.run.n_epochs += 1./self.iters\n",
    "        self.run.n_iter   += 1\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.run.n_epochs=self.epoch\n",
    "        self.model.train()\n",
    "        self.run.in_train=True\n",
    "\n",
    "    def begin_validate(self):\n",
    "        self.model.eval()\n",
    "        self.run.in_train=False\n",
    "\n",
    "class CancelTrainException(Exception): pass\n",
    "class CancelEpochException(Exception): pass\n",
    "class CancelBatchException(Exception): pass\n",
    "\n",
    "class TestCbsCallback(Callback):\n",
    "    def begin_fit(self):\n",
    "        print(\"I'm a test callback\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Learner and runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def param_getter(m): return m.parameters()\n",
    "\n",
    "def sgd_opt():\n",
    "    pass\n",
    "\n",
    "class LearnerRunnerDJ():\n",
    "    \n",
    "    def __init__(self, model, data, loss_func, opt_func=sgd_opt, lr=1e-2, splitter=param_getter,\n",
    "                 cbs=None, cb_funcs=None): # callback functions used to create callbacks\n",
    "        \n",
    "        # model - the model\n",
    "        # data \n",
    "        # loss func - usually cross entropy\n",
    "        # opt func - optimiser\n",
    "        self.model , self.data, self.loss_func, self.opt_func, self.lr, self.splitter = model, data, loss_func, opt_func,lr, splitter\n",
    "        \n",
    "        self.logger, self.in_train, self.opt = print, False, None # the logger is a print function to print the output from a nn\n",
    "        \n",
    "        self.cbs = []\n",
    "        self.add_cb(TrainEvalCallback())\n",
    "        self.add_cbs(cbs)\n",
    "        self.add_cbs(cbf() for cbf in listify(cb_funcs)) # goes through all callback creastor funcs and runs them\n",
    "        \n",
    "    def add_cbs(self, cbs):\n",
    "        for cb in listify(cbs): self.add_cb(cb) # call add cb on all callbacks\n",
    "            \n",
    "    def add_cb(self, cb):\n",
    "        cb.set_runner(self) # sets a 'pointer' to the runner inside the callback (so can access runner members such as)\n",
    "        #set_trace()\n",
    "        setattr(self, cb.name, cb) # set the callback as a member of the learner class\n",
    "        self.cbs.append(cb) # add the callback to the call backs list\n",
    "\n",
    "    def remove_cbs(self, cbs):\n",
    "        for cb in listify(cbs): self.cbs.remove(cb)\n",
    "            \n",
    "    def all_batches(self):\n",
    "        pass\n",
    "    \n",
    "    def one_batch(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self):\n",
    "        pass\n",
    "    def __call__(self):\n",
    "        res = False\n",
    "        assert cb_name in self.ALL_CBS\n",
    "        for cb in sorted(self.cbs, key=lambda x: x._order): res = cb(cb_name) and res\n",
    "        #set_trace()\n",
    "        return res # callback needs to return True to stop. With no return Python returns None (False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average stats call back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AvgStats(): # average stats is a class to calculate and store training stats (i.e accuracy)\n",
    "    def __init__(self, metrics, in_train): \n",
    "        self.metrics,self.in_train = listify(metrics),in_train\n",
    "        print(\"Metrics:\")\n",
    "        print(metrics)\n",
    "        \n",
    "    def reset(self):\n",
    "        self.tot_loss,self.count = 0.,0\n",
    "        self.tot_mets = [0.] * len(self.metrics)\n",
    "        \n",
    "    @property\n",
    "    def all_stats(self): return [self.tot_loss.item()] + self.tot_mets\n",
    "    @property\n",
    "    def avg_stats(self): return [o/self.count for o in self.all_stats]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if not self.count: return \"\"\n",
    "        return f\"{'train' if self.in_train else 'valid'}: {self.avg_stats}\"\n",
    "\n",
    "    def accumulate(self, run): # run is presumably the runner\n",
    "        bn = run.xb.shape[0] # xb is the mini batch\n",
    "        self.tot_loss += run.loss * bn # I think this is accounting for the batch size\n",
    "        self.count += bn\n",
    "        for i,m in enumerate(self.metrics): # applies the metric function to the prediction and the loss\n",
    "            self.tot_mets[i] += m(run.pred, run.yb) * bn # can have any metrics on the predictions and truth \n",
    "\n",
    "class AvgStatsCallback(Callback):\n",
    "    def __init__(self, metrics):\n",
    "        # train_stats and valid_stats are containers for stats for training and valdation sets\n",
    "        self.train_stats,self.valid_stats = AvgStats(metrics,True),AvgStats(metrics,False)\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.train_stats.reset()\n",
    "        self.valid_stats.reset()\n",
    "        \n",
    "    def after_loss(self): # after loss, the accumulates the loss on each mini batch\n",
    "        stats = self.train_stats if self.in_train else self.valid_stats\n",
    "        with torch.no_grad(): stats.accumulate(self.run)\n",
    "    \n",
    "    def after_epoch(self):\n",
    "        #We use the logger function of the `Learner` here, it can be customized to write in a file or in a progress bar\n",
    "        self.logger(self.train_stats)\n",
    "        self.logger(self.valid_stats) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "<function accuracy at 0x7f3c180e4d90>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x = Callback()\n",
    "tr = TrainEvalCallback()\n",
    "#x.__class__.__name__, x.name, tr.name\n",
    "\n",
    "\n",
    "def makeTestCB():\n",
    "    return TestCbsCallback()\n",
    "\n",
    "run = LearnerRunnerDJ(1, 2, 3, cb_funcs= makeTestCB)\n",
    "\n",
    "\n",
    "\n",
    "run.cbs[0].run, run.cbs[0].name, run.cbs[1].name, run.train_eval\n",
    "\n",
    "\n",
    "avgSts = AvgStats(accuracy, True)\n",
    "\n",
    "x = tensor([1, 2])\n",
    "y = tensor([[2, 6, 3], [2, 5, 3]])\n",
    "\n",
    "accuracy(y, x)\n",
    "\n",
    "avgSts.accuml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test():\n",
    "    \n",
    "    def print(self):\n",
    "        print(\"Hello\")\n",
    "        return True\n",
    "        \n",
    "    def __call__(self, func):\n",
    "        f = getattr(self, func, None)\n",
    "        print(f)\n",
    "        if f and f(): return True # note f() runs the function\n",
    "        return False\n",
    "    \n",
    "ttt = test()\n",
    "ttt('print')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
