{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's kill off `Runner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_09 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<class 'exp.nb_09.Optimizer'>, steppers=[<function weight_decay at 0x7f3a76ca90d0>, <function sgd_step at 0x7f3aecf326a8>])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AvgStats\n",
    "sgd_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagenette data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 11 video](https://course.fast.ai/videos/?lesson=11&t=6571)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = datasets.untar_data(datasets.URLs.IMAGENETTE_160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [make_rgb, ResizeFixed(128), to_byte_tensor, to_float_tensor]\n",
    "bs=64\n",
    "\n",
    "il = ImageList.from_files(path, tfms=tfms)\n",
    "sd = SplitData.split_by_func(il, partial(grandparent_splitter, valid_name='val'))\n",
    "ll = label_by_func(sd, parent_labeler, proc_y=CategoryProcessor())\n",
    "data = ll.to_databunch(bs, c_in=3, c_out=10, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(exp.nb_06.CudaCallback,\n",
       " exp.nb_05b.TrainEvalCallback,\n",
       " exp.nb_06.BatchTransformXCallback,\n",
       " <function exp.nb_04.listify(o)>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbfs = [partial(AvgStatsCallback,accuracy),\n",
    "        CudaCallback,\n",
    "        partial(BatchTransformXCallback, norm_imagenette)]\n",
    "CudaCallback, TrainEvalCallback, BatchTransformXCallback, listify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfs = [32]*4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a Runner is great but not essential when the `Learner` already has everything needed in its state. We implement everything inside it directly instead of building a second object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In Lesson 12 Jeremy Howard revisited material in the cell below  [Jump_to lesson 12 video](https://course.fast.ai/videos/?lesson=12&t=65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def param_getter(m): return m.parameters()\n",
    "\n",
    "class Learner():\n",
    "    def __init__(self, model, data, loss_func, opt_func=sgd_opt, lr=1e-2, splitter=param_getter,\n",
    "                 cbs=None, cb_funcs=None):\n",
    "        self.model,self.data,self.loss_func,self.opt_func,self.lr,self.splitter = model,data,loss_func,opt_func,lr,splitter\n",
    "        self.in_train,self.logger,self.opt = False,print,None\n",
    "        \n",
    "        # NB: Things marked \"NEW\" are covered in lesson 12\n",
    "        # NEW: avoid need for set_runner\n",
    "        self.cbs = []\n",
    "        self.add_cb(TrainEvalCallback())\n",
    "        self.add_cbs(cbs) # add callback class\n",
    "        self.add_cbs(cbf() for cbf in listify(cb_funcs)) # add call back creator functions\n",
    "\n",
    "    def add_cbs(self, cbs):\n",
    "        for cb in listify(cbs): self.add_cb(cb)\n",
    "            \n",
    "    def add_cb(self, cb):\n",
    "        cb.set_runner(self) \n",
    "        setattr(self, cb.name, cb)\n",
    "        self.cbs.append(cb)\n",
    "\n",
    "    def remove_cbs(self, cbs):\n",
    "        for cb in listify(cbs): self.cbs.remove(cb)\n",
    "            \n",
    "    def one_batch(self, i, xb, yb):\n",
    "        try:\n",
    "            self.iter = i\n",
    "            self.xb,self.yb = xb,yb;                        self('begin_batch')\n",
    "            self.pred = self.model(self.xb);                self('after_pred')\n",
    "            self.loss = self.loss_func(self.pred, self.yb); self('after_loss')\n",
    "            if not self.in_train: return\n",
    "            self.loss.backward();                           self('after_backward')\n",
    "            self.opt.step();                                self('after_step')\n",
    "            self.opt.zero_grad()\n",
    "        except CancelBatchException:                        self('after_cancel_batch')\n",
    "        finally:                                            self('after_batch')\n",
    "\n",
    "    def all_batches(self):\n",
    "        self.iters = len(self.dl)\n",
    "        try:\n",
    "            for i,(xb,yb) in enumerate(self.dl): self.one_batch(i, xb, yb)\n",
    "        except CancelEpochException: self('after_cancel_epoch')\n",
    "\n",
    "    def do_begin_fit(self, epochs):\n",
    "        self.epochs,self.loss = epochs,tensor(0.)\n",
    "        self('begin_fit')\n",
    "\n",
    "    def do_begin_epoch(self, epoch):\n",
    "        self.epoch,self.dl = epoch,self.data.train_dl\n",
    "        return self('begin_epoch')\n",
    "\n",
    "    def fit(self, epochs, cbs=None, reset_opt=False):\n",
    "        # NEW: pass callbacks to fit() and have them removed when done\n",
    "        self.add_cbs(cbs)\n",
    "        # NEW: create optimizer on fit(), optionally replacing existing\n",
    "        if reset_opt or not self.opt: self.opt = self.opt_func(self.splitter(self.model), lr=self.lr)\n",
    "            \n",
    "        try:\n",
    "            self.do_begin_fit(epochs)\n",
    "            for epoch in range(epochs):\n",
    "                self.do_begin_epoch(epoch)\n",
    "                if not self('begin_epoch'): self.all_batches()\n",
    "\n",
    "                with torch.no_grad(): \n",
    "                    self.dl = self.data.valid_dl\n",
    "                    if not self('begin_validate'): self.all_batches()\n",
    "                self('after_epoch')\n",
    "            \n",
    "        except CancelTrainException: self('after_cancel_train')\n",
    "        finally:\n",
    "            self('after_fit')\n",
    "            self.remove_cbs(cbs)\n",
    "\n",
    "    ALL_CBS = {'begin_batch', 'after_pred', 'after_loss', 'after_backward', 'after_step',\n",
    "        'after_cancel_batch', 'after_batch', 'after_cancel_epoch', 'begin_fit',\n",
    "        'begin_epoch', 'begin_validate', 'after_epoch',\n",
    "        'after_cancel_train', 'after_fit'}\n",
    "    \n",
    "    def __call__(self, cb_name):\n",
    "        res = False\n",
    "        assert cb_name in self.ALL_CBS\n",
    "        for cb in sorted(self.cbs, key=lambda x: x._order): res = cb(cb_name) and res\n",
    "        #set_trace()\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AvgStatsCallback(Callback):\n",
    "    def __init__(self, metrics):\n",
    "        self.train_stats,self.valid_stats = AvgStats(metrics,True),AvgStats(metrics,False)\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.train_stats.reset()\n",
    "        self.valid_stats.reset()\n",
    "        \n",
    "    def after_loss(self):\n",
    "        stats = self.train_stats if self.in_train else self.valid_stats\n",
    "        with torch.no_grad(): stats.accumulate(self.run)\n",
    "    \n",
    "    def after_epoch(self):\n",
    "        #We use the logger function of the `Learner` here, it can be customized to write in a file or in a progress bar\n",
    "        self.logger(self.train_stats)\n",
    "        self.logger(self.valid_stats) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbfs = [partial(AvgStatsCallback,accuracy),\n",
    "        CudaCallback,\n",
    "        partial(BatchTransformXCallback, norm_imagenette)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_learner(nfs, data, lr, layer, loss_func=F.cross_entropy,\n",
    "                cb_funcs=None, opt_func=sgd_opt, **kwargs):\n",
    "    model = get_cnn_model(data, nfs, layer, **kwargs)\n",
    "    init_cnn(model)\n",
    "    return Learner(model, data, loss_func, lr=lr, cb_funcs=cb_funcs, opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "<function accuracy at 0x7f3ad018fae8>\n",
      "Metrics:\n",
      "<function accuracy at 0x7f3ad018fae8>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function print>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = get_learner(nfs, data, 0.4, conv_layer, cb_funcs=cbfs)\n",
    "learn.cbs, learn.avg_stats, \n",
    "learn.logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [1.8547163712288661, tensor(0.3459, device='cuda:0')]\n",
      "valid: [1.8653887939453124, tensor(0.3680, device='cuda:0')]\n",
      "CPU times: user 28.4 s, sys: 9.23 s, total: 37.7 s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%time learn.fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check everything works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our previous callbacks still work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbfs += [Recorder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "<function accuracy at 0x7f3ad018fae8>\n",
      "Metrics:\n",
      "<function accuracy at 0x7f3ad018fae8>\n"
     ]
    }
   ],
   "source": [
    "learn = get_learner(nfs, data, 0.4, conv_layer, cb_funcs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cos_1cycle_anneal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-bba10b71f43e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mphases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_scheds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcos_1cycle_anneal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParamScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cos_1cycle_anneal' is not defined"
     ]
    }
   ],
   "source": [
    "phases = combine_scheds([0.3, 0.7], cos_1cycle_anneal(0.2, 0.6, 0.2))\n",
    "sched = ParamScheduler('lr', phases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1, sched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./notebook2script.py 09b_learner.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
